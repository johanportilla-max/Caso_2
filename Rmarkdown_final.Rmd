---
title: "Modelos de Clasificación para Riesgo Crediticio"
author: "Barros Rayo Alejandro (2415837), Muñoz Portela Diego Fernando (2415620), Portilla Aguirre Johan Camilo (2422468), Aguirre Aldana Joan Sebastian (2419550)"
output: 
  html_document:
    theme: lumen
    highlight: textmate
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
    toc_depth: 3
    number_sections: true
    code_folding: show
---
# Introducción


# Metodología

## Fuente de datos 
## Definición de variables


## Preparación y limpieza de datos 
# Análisis descriptivo



## Distribución de las variables principales
## Caracterización de las clases
## Comportamiento según propósito del préstamo
# Modelos de clasificación
## División de los datos

Para el desarrollo de los modelos de clasificación, se realizó un muestreo estratificado balanceado seguido de una partición aleatoria, con el objetivo de mitigar el desbalance inherente en el dataset original de Lending Club, donde aproximadamente el 82% de las observaciones corresponden a préstamos pagados y solo el 18% a incumplimientos, lo que podría sesgar los algoritmos hacia la clase mayoritaria. Inicialmente, de la base filtrada y limpia ("lending_base"), se extrajo una muestra aleatoria de 10,000 observaciones utilizando sample_n() en R con semilla fija (set.seed(28)) para reproducibilidad: 5,000 de la clase "Paga" y 5,000 de "No_paga", aplicando undersampling a la clase dominante para igualar las proporciones y mejorar la sensibilidad de los modelos en la detección de riesgos crediticios. Esta técnica de balanceo es estándar en problemas de clasificación binaria desbalanceada, como los de préstamos P2P, ya que permite evaluaciones más robustas de métricas como precisión, recall y AUC sin requerir oversampling sintético.

Posteriormente, la muestra balanceada ("lending_muestra") se dividió en subconjuntos de entrenamiento (75% de las observaciones, equivalente a 7,500 registros) y prueba (25%, o 2,500 registros), utilizando sample() con la misma semilla para mantener la aleatoriedad controlada y preservar el equilibrio equitativo entre clases en ambos conjuntos (aproximadamente 50% "Paga" y 50% "No_paga"). La proporción 75/25 es una convención común en machine learning para clasificación, ya que proporciona suficientes datos para el entrenamiento mientras reserva un conjunto de prueba independiente para validar el rendimiento generalizado, evitando sobreajuste en datasets de riesgo crediticio como el de Lending Club. Esta división se implementó mediante índices aleatorios (index_entrena e index_test), asegurando que las variables predictoras (numéricas y categóricas) se mantuvieran representativas en ambos subconjuntos para una evaluación imparcial de los modelos KNN y logit.

## Modelo KNN

El modelo K-Nearest Neighbors (KNN) es un algoritmo de aprendizaje supervisado no paramétrico, ampliamente utilizado para problemas de clasificación, donde predice la clase de un nuevo punto de datos basándose en la mayoría de clases de sus k vecinos más cercanos en el espacio de características. Este método opera de manera "perezosa", ya que no construye un modelo explícito durante el entrenamiento, sino que almacena el conjunto de datos y realiza cálculos de distancia (como la euclidiana) solo en el momento de la predicción, lo que lo hace simple e intuitivo para capturar patrones locales en los datos.

### Modelo KNN (class)

El modelo KNN fue entrenado utilizando únicamente variables numéricas estandarizadas 
(`ingreso`, `relación deuda/ingreso`, `monto del préstamo`, y `puntaje FICO`).  
Se evaluaron diferentes valores de *k* (número de vecinos)

### Modelo KNN (caret)
## Modelo Logit

El modelo de regresión logística (logit) es un algoritmo de aprendizaje supervisado paramétrico diseñado principalmente para clasificación binaria, que estima la probabilidad de que una observación pertenezca a una clase específica (por ejemplo, pago o no pago) mediante la aplicación de la función sigmoide a una combinación lineal de las variables predictoras. A diferencia de la regresión lineal, transforma las salidas en valores entre 0 y 1, permitiendo interpretaciones probabilísticas y umbrales para decisiones de clasificación, lo que lo hace ideal para modelar relaciones no lineales en datos categóricos.


# Comparación de modelos
# Conclusiones 
# Bibliografia 
rfirawvjbkwbj
```{r setup, include=FALSE}



knitr::opts_chunk$set(echo = TRUE)
```

```{r cars}
```



```{r pressure, echo=FALSE}
```

